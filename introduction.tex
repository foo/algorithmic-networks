\indent\textbf{\emph{Paradigm shift in computing.}}
In the last decade, we witnessed a growing demand to perform large-scale
computations, such as protein folding, fluid dynamics, weather prediction and
wide range of optimization for military and industry.
The scale of such computations exceedes abilities of a single computer, hence computations are performed on large sets of machines that cooperate over interconnecting network, collectively called the \emph{computer cluster}.
Owning and maintaing such infrastructure is often impractical and expensive, and parties look for alternative ways to perform computations.
Outsourcing such computations provides a wide range of benefits.
First of all, it mitigates the costs of infrastructure management and maintenance.
This is crucial especially for computational tasks that arise occasionally, such as optimizations for industries \maciek{More examples needed. Those listed before are naive to list as occasional}.
In addition, it dismisses the need to foresee the appropriate demand for resources.
If the demand for resources increases unexpectedly, it can be immediately provided without physical extension of the infrastructure.
Above rationalities combined led to shift the computations to large, dedicated and remote computer clusters that are called \emph{data centers}, and coined the term \emph{cloud computing}.\maciek{the last ``and'' would need parethesis}

The demand for outsourcing computations to the cloud created a whole market for such services.
Modern general-purpose and open for general use data centers such as Microsoft Azure \cite{url-azure}, Amazon Elastic Cloud Computing EC2 \cite{url-amazon-ec2} or Google Compute Engine \cite{url-gce} provide convenient on-demand computational power while hiding most of details concerning resource management.

Computational tasks require multiple types of resources to complete: CPU time, memory, I/O operations and network bandwith.
Demand for resources often vary in time and is unpredictable or expensive to predict.
For this reason, the data center that performs \emph{just one task at the time} are doomed to waste resources.
However, co-existence of multiple tasks in the data center allows to compensate for the variable demand for resources of computational tasks by resource-aware scheduling.
Such techniques are especially useful in (but not limited to) computationally-intensive applications, where the response time is not the primary concern.

\emph{From the perspective of an data center owner}, the main goal 
is an efficient management of resources. This is interwined with 
a multitude of problems and requirements: security in resource-sharing scenarios,
standarization and compatibility, automation, availability, extensibility and
modularity, recovery, and many more. An important class of new challenges in
data center is \emph{optimization of resource usage}. In particular, 
processing speed can
scale down to save energy, memory can be shared or distributed, and cooperating
processes can migrate closer in the network to save bandwidth.

\section{Machine virtualization}

This computational paradigm shift is strongly connected with the advancements 
in the underlying computational infrastructure, both in hardware and in software. 
The processing capabilities of data centers 
would not be possible without improvements in
task isolation, resource sharing and transparent concurrency.
The software advancements played the
primal role in allowing data centers to grow without wasting its resources.

A particular piece of technology that suits the model of modern data center extraordinarly well is virtualization.
Virtualization provides an abstraction layer for the underlying hardware of a computer system, called the \emph{virtual machine}.
Virtual machine mimics functionality of the physical hardware so closely and
directly that it can be used as an environment for a complete operating system.
Such operating system, running on a virtual machine is called the \emph{guest
operating system}. It operates in additon to the \emph{host operating
system}, which operates directly on the physical hardware. 

Mature virtualization solutions are available for data center usage: Xen
\cite{url-xen}, KVM \cite{url-kvm}, Hyper-V \cite{url-hyperv}, VMware ESXi
\cite{url-vmware}. The perspective of the guest
operating system is restricted to such exposed virtual machine and is provided
with an illusion of possesing the whole computer system. The main features of
virtualization in datacenter is \emph{to provide the complete and
non-restricted environment} for the client that is isolated from the management
software and other clients' tasks.

Besides providing an abstraction layer, virtualization provides several
control features. Absolute control over the underlying, virtual hardware of
the guest operating system allows to suspend and resume the execution of the
guest operating system at will. Such functionality provides building blocks
for the feature of migration, which transfers the complete virtual machine to
a different physical machine. Possibility of migration plays an important role
in load balancing in the data center and allows for sophisticated
optimizations such as reducing network distance between communicating virtual
machines.

Data center consists of multiple virtual machines running on physical nodes
that are connected by physical network. Single virtual machine often provides
insufficient resources for the client, as its resources are limited by resources
available to its host. Data centers provide its resources to clients as a set
of virtual machines connected by a network. The network that connects virtual
machines is restricted and controlled in similar manner to hardware
virtualization, and is called a \emph{virtual network}. Cooperating virtual
machines are often refered to as a \emph{nodes} of a virtual network. To
guarantee certain quality of service (\emph{QoS}), up-front bandwidth
reservations are a requisite. However, the generality of performed calculations
results in unpredictibility of communication patterns and poses a challenge in
optimization of bandwidth reservations.

Virtualization allows
flexibility in renting infrastructure, and might offer savings in resource
management. However, efficient use of resources requires sophisticated
techniques to achieve its goal. In this thesis, we focus on using the tools
provided by modern virtualization techologies for efficient usage of important
resource in the data center -- the network bandwidth. Problem central to this
thesis is stated as follows:

\begin{center}
  \emph{How to assign virtual machines to physical machines to optimize network
  usage?}
\end{center}

We elaborate more in subsequent subsection.

\section{Algorithmic aspects of the virtual machines embedding}

To state optimization problems, we model certain aspects of data center operation.
Physical components of a data center are often modelled in form of a graph called a \emph{substrate network}, in which vertices correspond to \emph{physical machines}, and edges correspond to \emph{network interconnect}.
Communication cost between pair of physical machines is proportional to edge-distance in substrate network (the number of \emph{hops} in the substrate network).
Communication pattern among virtual machines is also modelled as a graph, called a \emph{communication graph}.
In such settings, the communication among virtual machines running on certain physical machines is modelled as a \emph{graph embedding} of communication graph into a substrate network.
In optimization of network usage, the objective function is the total cost of such embedding, measured in size of multiset of used edges of the host graph.

In this thesis we consider substrate networks in form of a tree, which models closely the popular topology of a Fat-Tree, but fails to approximate some sophisticated topologies such as a Butterfly Topology.
In the tree topology, we distinguish a specific class of physical machines that cannot host virtual machines, and their sole role is to transmit communication patterns.
Machines that are able to host virtual machines are placed in leaves of the substrate graph.


\begin{figure}[t]
\centering
\includegraphics[width=0.79\columnwidth]{figs/tree-topology.pdf}
\caption{The model of typical data center.}\label{fig:overview}
\vspace{-1em}
\end{figure}

\section{Algorithmics aspects of network optimization}

TODO Tree Caching

\section{Contributions of this thesis and thesis organization}

In this thesis we consider two scenarios regarding virtual machines embeddings:
\begin{enumerate}
  \item The communication pattern among virtual machines is known up-front
  \item The communication pattern is not known, and has to be discovered and is a subject to changes over time
\end{enumerate}

\maciek{I realised that the paragraph below is wrong. In both cases the communication pattern is not known. The difference lies in how we proceed: either we try to discover patters, or we make complete graph reservations}

Consider the scenario, where the communication pattern is not known.
In order to guarantee certain quality of service (\emph{QoS}), we need to acquire network reservations for \emph{all} possible communication patterns among cooperating virtual machines.
Hence, in such scenario, we consider the worst-case communication graph in form of a clique.
The combinatorial problem that we consider in Part 1 is essentially the minimum-cost embedding of a clique in a tree, enriched by certain extensions motivated by Map-Reduce applications.
We consider the wide range of possible extensions, most notably:

\begin{itemize}
\item \emph{Data chunk processing}. In Map-Reduce applications, set of virtual machines processes large amounts of data that are stored in distributed file system. Each chunk of data must be assigned and transferred to a virtual machine. Data chunk transfer requires its own network reservations.

\item \emph{Data chunk replication}. Distributed file systems often store redundant copies of data chunks, called \emph{chunk replicas}. Only one copy of each data chunk replica must be processed, and we are free to choose the replica based on its placement.

\item \emph{Bandwidth constraints}. Each link in substrate network has its capacity. For the embedding to be feasible, the total network reservations has to obey link capacities.
\end{itemize}

Consider the scenario, where the communication pattern is not known.
Migration.



\input{contribution}

\subsection{Performance metrics}

Methods of Measuring the Quality of Results

\subsubsection{Online Algorithms and Competitive Analysis}

Sleator, Tarjan: list update \cite{competitive-analysis}
Borodin book \cite{borodin-book}

\subsubsection{Time and Space Complexity and NP-completeness}


\section{Related Work}

\input{related-work}



\section{Bibliographic notes}

Parts of this thesis were co-published by the author of this thesis in the following conferences and journals: ICNP TODOCITE, ACM SPAA TODOCITE, DISC TODOCITE and Journal of Theoretical Computer Science TODOCITE.
In addition, parts of this thesis were published in Alexandra Spyra's master thesis and Carlo Fuerst's doctorial thesis.