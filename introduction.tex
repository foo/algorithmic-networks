\indent
In the last decade, we witnessed a growing demand to perform large-scale
computations, such as protein folding, fluid dynamics, weather and market prediction, or production process optimization.
The scale of such computations exceedes abilities of a single computer, hence computations need to be performed on large sets of machines that cooperate over interconnecting network, collectively called the \emph{computer cluster}.
Owning and maintaing large-scale computing infrastructure is often impractical and expensive, and parties look for alternative ways to perform computations.
In comparison, outsourcing computations provides a wide range of benefits.
First of all, it mitigates the costs of infrastructure management and maintenance.
This is crucial especially for computational tasks that arise occasionally, such as high-quality rendering, computer verification of products with long development time or analysis of human-harvested data.
Second, such approach dismisses the need to foresee the appropriate demand for resources.
If the demand for resources increases unexpectedly, it can be immediately provided without physical extension of the infrastructure.
This led to shift of computations to large-scale \emph{remote} facilites that contain computer clusters with their support infrastructure, the so-called \emph{data centers}.
Performing computations in these external data centers provides the impression of unlimited computational power on demand, and is called the \emph{cloud computing}.

The demand for outsourcing computations to the cloud created a whole market for such services.
Modern processing power suppliers such as Microsoft Azure \cite{url-azure}, Amazon Elastic Cloud Computing EC2 \cite{url-amazon-ec2} or Google Compute Engine \cite{url-gce} provide convenient on-demand computational power while hiding most of details concerning resource management.
Processing capabilities are quickly and conveniently accessible to every interested party.

Computational tasks require multiple types of resources to complete: CPU time, memory, I/O operations and network bandwith.
Demand for these resources often vary in time and is unpredictable.
For this reason, a data center that performs \emph{just one task at the time} would be doomed to waste resources.
However, the co-existence of multiple tasks in the data center allows to compensate for the variable demand for resources by resource-aware scheduling.
Such techniques are especially useful in (but not limited to) computationally-intensive applications, where the response time is not the primary concern.

The first part of this thesis assumes the perspective of a data center owner, whose main goal is an \emph{efficient management of resources}.
For example, processing speed can scale down to save energy, memory can be shared or distributed, and cooperating processes can migrate closer in the network to save bandwidth.
In the first part of this thesis, we focus on the last aspect and we show how it leads to
\emph{efficient usage of interconnecting network} in a data center.
Optimization of this resource is critical to perform efficient large-scale computations, as those involve multiple machines that cooperate over network.
To this end, we will make use of a sophisticated control system, called \emph{virtualization}, which is described in Section~\ref{sec:intro-machine-virtualization}


In the second part of this thesis, we shift our attention away from virtual network embeddings and focus on fundamental aspects of \emph{packet transmission}.
Growth of the Internet, witnessed in recent decades, lied emphasis on new aspects of packet transmission.
In particular, packets travel across multiple networks to reach their destination.
Single computer network is often connected with multiple adjacent networks, and at each intermediate network we need to determine the next network on the way of the packet.
Virtual clusters described in the first part of this thesis further contribute to such view of the Internet.

The fundamental operation of deciding, to which of adjacent networks to rely the packet is called a \emph{packet forwarding}.
Packet forwarding becomes the crucial operation to optimize, especially in contact points among large networks.
Physical components of the Internet that exchanges data on a large scale between large networks are called \emph{Internet exchange points (IXP)}.
The second part of this thesis assumes the perspective of Internet exchange point owner, whose objective is to \emph{maximize the efficiency of packet forwarding}, see Section~\ref{sec:intro-packet-forwarding}.

\section{Machine virtualization}
\label{sec:intro-machine-virtualization}

Techniques presented in this thesis rely upon logical isolation of a computation from the physical machine that performs the computation.
This gives a possibility to manage the physical placement of a computation in a way that is transparent to the computation, and hence \todo{mozna przemieszczac zeby byly blisko siebie lub blisko danych z ktorych korzystaja}
A particular piece of technology that provided the flexibility in placement of computations is \emph{virtualization}.

Virtualization provides an abstraction layer for the underlying hardware of a computer system, called the \emph{virtual machine}.
Virtual machine mimics functionality of the physical hardware so closely and
directly that it can be used as an environment for a complete operating system.
Such operating system, running on a virtual machine is called the \emph{guest
operating system}. It operates in additon to the \emph{host operating
system}, which operates directly on the physical hardware. 

\subsection{Machine migration}

In a data center, the main purpose of virtualization is to provide the complete and non-restricted environment for the client that is isolated from the management software and other clients' tasks.
The perspective of the guest operating system is restricted to such exposed virtual machine and is provided with an illusion of possesing the whole computer system.\todo{I think that this paragraph should be moved to ``machine virtualization''}


Besides providing an abstraction layer, mature virtualization solutions suited for data center use such as Xen
\cite{url-xen}, KVM \cite{url-kvm}, Hyper-V \cite{url-hyperv}, VMware ESXi
\cite{url-vmware} provide several control features.
In particular, absolute control over the underlying virtual hardware allows to suspend and resume the execution of the guest operating system at will.
Such functionality provides building blocks for the feature of \emph{migration}, which transfers the complete virtual machine to a different physical machine.
This is possible without shutting down the guest operating system, hence it provides a powerful resource-management tool that is transparent to clients.
Such mechanisms play an important role in load balancing in the data center and allows for sophisticated optimizations such as \emph{reducing network distance between communicating virtual machines}.

Virtualization allows flexibility in renting infrastructure, and might offer savings in resource management.
However, efficient use of resources requires sophisticated techniques to achieve its goal.
In this thesis, we focus on migration capabilities provided by modern virtualization techologies for efficient usage of important resource in the data center -- the network bandwidth.
The problem central to this thesis is stated as follows:

\begin{center}
  \emph{How to assign virtual machines to physical machines to optimize network
  usage?}
\end{center}

We elaborate more in the subsequent subsection.

\subsection{Virtual network embedding}

Single virtual machine often provides insufficient resources for the client, as the resources of a virtual machine are limited by resources available to its host.
Therefore, data centers provide its resources to clients as a set
of virtual machines connected by a network.
Collectively, the virtual machines with their interconnecting network are called a \emph{virtual network}, where the cooperating virtual machines are refered to as a \emph{nodes} of a virtual network.
To guarantee certain quality of service (\emph{QoS}) for multitude of co-existing virtual networks, up-front bandwidth reservations are required.
However, the generality of performed calculations results in unpredictibility of communication patterns and poses a challenge in optimization of bandwidth reservations.
In this thesis, we provide algorithms for efficient management of network reservations without any assumptions about communication patterns.

To measure the quality of resource management strategy, we state formal optimization problems that we specify in further sections.
For now, we briefly sketch the combinatorial model of a data center.
Physical components of a data center are often modelled in form of a graph called a \emph{substrate network}, in which vertices correspond to physical machines, and edges correspond to interconnecting network.
Communication cost between pair of physical machines is proportional to edge-distance in substrate network (the number of \emph{hops} in the substrate network).
Communication pattern among virtual machines is also modelled as a graph, called a \emph{communication graph}.
In such settings, the communication among virtual machines running on certain physical machines can be viewed as a \emph{graph embedding} of communication graph into a substrate network~\cite{Goyal2008,gupta2001provisioning}.
The objective is to find such embedding that locates closely the virtual machines that communicate often.

In this thesis we consider substrate networks in form of a tree, which models closely the popular Fat-Tree topology~\cite{fat-trees}.
In this tree topology, only leaves can host virtual machines.
The sole role of intermediate tree nodes is to transmit communication between leaves, see Figure~\ref{fig:tree-topology}.\todo{Remove circles, squares and communication}


\begin{figure}[h]
\centering
\includegraphics[width=0.79\columnwidth]{figs/tree-topology.pdf}
\caption{The model of typical data center with tree-like network topology. We distinguish two types of tree nodes: the the intermediate nodes that transmit communication, and the physical machines, located at the leaves of a tree. Network links between nodes are depicted as solid lines.}\label{fig:tree-topology}
\vspace{-1em}
\end{figure}

\section{Packet forwarding}
\label{sec:intro-packet-forwarding}

For this section, we shift our attention away from virtual network embeddings and focus on fundamental problem of \emph{packet forwarding}.
Consider a network device that is responsible for transmitting packets such as router or switch.
Such device physically connects parts of the network by the endpoints of the device, which are identified by the port number.
Upon receiving a packet, the device forwards it to a specific port that corresponds to the part of the network, where the recipient of the packet lies.
In its memory, the device keeps track of mapping the recipent's addresses to ports, called a \emph{forwarding table}.

To .., we need to investigate the internal composition of a router.
Routers have finite memory. TCAM memory.

Router + PC that holds data. The memory of the router acts as a cache. PC can update. OpenFlow protocol.

Cache miss of the packet: mechanics.




The network device has finite memory, and in multiple scenarios the size of forwarding table exceeds the size of available memory.
In such scenario, the packet still needs to reach its destination.
The usual response is to broadcast the packet to all of its ports, which has negative effects on performance of the network, as excessive packets increase the chance of packet collision.

Known solutions to increase performance of packet forwarding address the problem by compression of the forwarding table, which results in lower miss ratio.
However, recent raise of centrally-managed networks called \emph{Software Defined Networking (SDN)} allowed new approaches to the problem.
In SDN, the logic of network management is separated from the devices, whose sole responsibility is packet forwarding.
Network management is accomplished by central component called the \emph{SDN Controller}, rather by distributed cooperation of network devices.
The controller has the complete view of the network, which includes the full knowledge of network topology, that allows to produce complete forwarding table for each forwarding device.
In such scenario, the forwarding device's memory acts as a cache for the forwarding table that is stored remotely at the controller.
At the cache miss, the packet is forwarded to the controller, which performs two operations: (a) it properly forwards the packet to the receiver and (b) if the controller decides to do so, it updates the forwarding device's cache.

In this thesis, we focus on the following problem:
\begin{center}
  \emph{How to efficiently manage the memory of forwarding devices?}
\end{center}

Cache management poses multiple challenges:
\begin{itemize}
  \item When the controller decides that the forwarding device's cache should contain a forwarding entry, which of cached entries to evict?
  \item How to efficiently deal with changes in network topology?
\end{itemize}

Such applications are especially useful in Internet Exchange Points.

\section{Contributions of this thesis and thesis organization}

In the first part of this thesis we consider two scenarios regarding virtual network embeddings:
\begin{enumerate}
  \item \emph{The static scenario}, where virtual machines are irrevocably assigned to their physical machines at the moment of creation of virtual nodes (Section~\ref{sec:contributions-static-mapping}).
  \item \emph{The dynamic scenario}, where virtual machines can migrate between physical machines (Section~\ref{sec:contributions-dynamic-mapping}).
\end{enumerate}
In both scenarios we assume that the communication pattern among virtual nodes is not known in advance.
The static scenario, to guarantee certain quality of service (\emph{QoS}), we need to acquire network reservations for \emph{all} possible communication patterns among cooperating virtual machines.
The combinatorial problem that we consider in the static scenario is essentially the minimum-cost embedding of a clique in a tree, enriched by certain extensions motivated by Map-Reduce applications.
On the other hand, in the dynamic scenario, we rearrange the placement of virtual nodes in reply to changes in communication pattern, and we need to minimize the sum of migration and communication costs.

In the second part of this thesis we consider the problem of memory management of routing devices.
Our approach is to develop a caching scenario, which we describe in Section~\ref{sec:contributions-packet-forwarding}.
\todo{Popraw te dwa zdania}

\subsection{Contributions on Static Mapping}
\label{sec:contributions-static-mapping}

In Chapter~\ref{ch:static-mapping}, we study the data-locality and replica aware virtual network embedding problems in datacenters.
The model we consider is a variant of graph embedding problem, where the host graph is a tree, and a guest graph consists of union of a clique and a matching.
We consider the wide range of possible extensions that model certain aspects of Map-Reduce applications, most notably:

\begin{itemize}
\item \emph{Data chunk processing}. In Map-Reduce applications, set of virtual machines processes large amounts of data that are stored in distributed file system. Each chunk of data must be assigned and transferred to a virtual machine. Data chunk transfer requires its own network reservations.

\item \emph{Data chunk replication}. Distributed file systems often store redundant copies of data chunks, called \emph{chunk replicas}. Only one copy of each data chunk replica must be processed, and we are free to choose the replica based on its placement.

\item \emph{Bandwidth constraints}. Each link in substrate network has its capacity. For the embedding to be feasible, the total network reservations has to obey link capacities.
\end{itemize}


In particular, we decompose the general optimization problem into its fundamental aspects, such as
assignment of chunks, replica selection, and flexible virtual machine
placement, and answer questions such as:
\begin{enumerate}
\item Which chunks to assign to which virtual machine?

\item How to exploit redundancy and select good replicas?

\item How to efficiently embed virtual machines and their inter-connecting network?

\item Can the chunk assignment, replica selection and virtual machine embedding problems be jointly optimized, in polynomial time?
\end{enumerate}

We draw a complete picture of the problem space: we show that
even problem variants exhibiting multiple degrees of freedom in terms of
replica selection and embedding,
can be solved optimally in polynomial time, and we present several efficient
algorithms accordingly. However, we also prove limitations in terms of
computational tractability, by providing reductions from 3-D matching
and Boolean satisfiability ($\SAT$). Interestingly,
while it is well-known that (unsplittable) multi-commodity flow
problems are NP-hard in capacitated networks, our hardness results also hold in \emph{uncapacitated}
networks; moreover, we show that NP-hard problems already arise in small-diameter networks (as they are
widely used today~\cite{fattree}).

\newpage

\subsection{Contributions on Dynamic Mapping}
\label{sec:contributions-dynamic-mapping}

The model we consider is a variant of online graph clustering.
Certain assumptions such as 1-level tree. Hierarchical structure modeled by hosting multiple vms on one pm.
Competitive analysis.

Sleator, Tarjan: list update \cite{competitive-analysis}
Borodin book \cite{borodin-book}


\subsection{Contributions on Memory Management in Network Devices}
\label{sec:contributions-packet-forwarding}

Sleator, Tarjan: list update \cite{competitive-analysis}
Borodin book \cite{borodin-book}



\section{Related Work}

\input{related-work}



\section{Bibliographic notes}

Parts of this thesis were co-published by the author of this thesis in the following conferences and journals: ICNP~2015~\cite{my-icnp}, DISC~2016~\cite{my-disc}, ACM~SPAA~2017~\cite{my-spaa}, and Journal of Theoretical Computer Science~\cite{my-tcs}.
In addition, parts of this thesis were published in Alexandra Spyra's master thesis and Carlo Fuerst's doctorial thesis.